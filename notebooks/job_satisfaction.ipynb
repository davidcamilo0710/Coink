{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
       "0                 1          2  Life Sciences              1               1   \n",
       "1                 8          1  Life Sciences              1               2   \n",
       "2                 2          2          Other              1               4   \n",
       "\n",
       "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
       "0  ...                         1            80                 0   \n",
       "1  ...                         4            80                 1   \n",
       "2  ...                         2            80                 0   \n",
       "\n",
       "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                  8                      0               1               6   \n",
       "1                 10                      3               3              10   \n",
       "2                  7                      3               3               0   \n",
       "\n",
       "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                  4                        0                     5  \n",
       "1                  7                        1                     7  \n",
       "2                  0                        0                     0  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import warnings\n",
    "from IPython.display import IFrame\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_excel(\"../data/info_satisfaccion_trabajo.xlsx\")\n",
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __EDA with pandas_profiling__ \n",
    "\n",
    "[EDA with pandas_profiling](https://davidcamilo0710.github.io/Coink)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate report using pandas-profiling\n",
    "# report = df.profile_report()\n",
    "\n",
    "# # Save the report to an HTML file\n",
    "# report.to_file(\"report.html\")\n",
    "\n",
    "# # View the report in the notebook\n",
    "# IFrame(src='report.html', width=1000, height=600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The report shows that the dataset contains 1470 observations and 35 variables, with 15 being numeric, 3 boolean, and 17 categorical. No missing cells or duplicate rows were found in the dataset.\n",
    "\n",
    "The Alerts highlight some important characteristics of the dataset, including the presence of constant variables (EmployeeCount, Over18, StandardHours), and high correlations between several numeric variables, such as Age with TotalWorkingYears, MonthlyIncome with TotalWorkingYears and one other variable, PercentSalaryHike with PerformanceRating, among others. There is also high correlation between categorical variables like Department and EducationField, and JobRole and Department.\n",
    "\n",
    "Overall, the pandas_profiling report provides valuable information about the dataset characteristics, including the distribution and type of variables, as well as relationships and correlations between them. It also detects constant variables and missing or zero values. This information will be useful for developing the requested supervised learning models and save some time.\n",
    "\n",
    "### Resumamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------+-----------------------+\n",
      "|                               Issue                                |        Details        |\n",
      "+--------------------------------------------------------------------+-----------------------+\n",
      "|                    Number of rows and columns:                     | 1470 rows, 35 columns |\n",
      "|                       Number of null values:                       |         None          |\n",
      "|                       Number of duplicates:                        |         None          |\n",
      "|                    Columns with many outliers:                     |                       |\n",
      "|                         PerformanceRating                          |        15.37%         |\n",
      "|                                                                    |                       |\n",
      "|                  Imbalanced categorical columns:                   |                       |\n",
      "|                             Department                             |                       |\n",
      "|                           EducationField                           |                       |\n",
      "|                              JobRole                               |                       |\n",
      "|                                                                    |                       |\n",
      "|           Categorical columns that need encoding for ML:           |                       |\n",
      "| BusinessTravel, Department, EducationField, JobRole, MaritalStatus |                       |\n",
      "|                                                                    |                       |\n",
      "|             Boolean columns that need encoding for ML:             |                       |\n",
      "|                    Attrition, Gender, OverTime                     |                       |\n",
      "|                                                                    |                       |\n",
      "|                Columns with only one unique value:                 |                       |\n",
      "|                EmployeeCount, Over18, StandardHours                |                       |\n",
      "+--------------------------------------------------------------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "def dataframe_summary(df):\n",
    "    # Number of rows and columns\n",
    "    summary = []\n",
    "    summary.append([\"Number of rows and columns:\", f\"{df.shape[0]} rows, {df.shape[1]} columns\"])\n",
    "    \n",
    "    # Number of null values\n",
    "    null_counts = df.isnull().sum()\n",
    "    if null_counts.sum() > 0:\n",
    "        null_cols = null_counts[null_counts > 0]\n",
    "        summary.append([\"Number of null values:\", f\"{null_counts.sum()} in total across {len(null_cols)} columns\"])\n",
    "    else :\n",
    "        summary.append([\"Number of null values:\", \"None\"])\n",
    "        \n",
    "    # Number of duplicates\n",
    "    num_duplicates = df.duplicated().sum()\n",
    "    if num_duplicates > 0:\n",
    "        summary.append([\"Number of duplicates:\", f\"{num_duplicates}\"])\n",
    "    else:\n",
    "        summary.append([\"Number of duplicates:\", \"None\"])\n",
    "    \n",
    "    # Columns with many outliers\n",
    "    outlier_threshold = 3\n",
    "    outliers_summary = []\n",
    "    for col in df.select_dtypes(include=np.number).columns:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        interquartile_range = q3 - q1\n",
    "        outliers = ((df[col] < q1 - outlier_threshold*interquartile_range) | (df[col] > q3 + outlier_threshold*interquartile_range))\n",
    "        outlier_percentage = outliers.sum()/df.shape[0]\n",
    "        if outlier_percentage > 0.05:\n",
    "            outliers_summary.append([col, f\"{outlier_percentage:.2%}\"])\n",
    "    \n",
    "    if outliers_summary:\n",
    "        summary.append([\"Columns with many outliers:\", \"\"])\n",
    "        summary.extend(outliers_summary)\n",
    "        summary.append([\"\", \"\"])\n",
    "    \n",
    "    # Imbalanced columns\n",
    "    imbalanced_summary = []\n",
    "    for col in df.select_dtypes(include=[\"object\", \"category\"]).columns:\n",
    "        if df[col].nunique() > 2:\n",
    "            value_counts = df[col].value_counts(normalize=True)\n",
    "            if (value_counts < 0.05).any():\n",
    "                imbalanced_summary.append([col, \"\"])\n",
    "    \n",
    "    if imbalanced_summary:\n",
    "        summary.append([\"Imbalanced categorical columns:\", \"\"])\n",
    "        summary.extend(imbalanced_summary)\n",
    "        summary.append([\"\", \"\"])\n",
    "    \n",
    "    # Categorical columns that need encoding\n",
    "    cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    cat_cols_to_encode = [col for col in cat_cols if len(df[col].value_counts()) > 2]\n",
    "    if cat_cols_to_encode:\n",
    "        summary.append([\"Categorical columns that need encoding for ML:\", \"\"])\n",
    "        summary.append([\", \".join(cat_cols_to_encode), \"\"])\n",
    "        summary.append([\"\", \"\"])\n",
    "    else:\n",
    "        summary.append([\"All categorical columns are encoded for ML.\", \"\"])\n",
    "        summary.append([\"\", \"\"])\n",
    "    \n",
    "    # Binary columns that need encoding\n",
    "    binary_cols = [col for col in df.columns if len(df[col].value_counts()) == 2]\n",
    "    binary_cols_to_encode = [col for col in binary_cols if df[col].dtype == \"object\" or df[col].dtype.name == \"category\"]\n",
    "    if binary_cols_to_encode:\n",
    "        summary.append([\"Boolean columns that need encoding for ML:\", \"\"])\n",
    "        summary.append([\", \".join(binary_cols_to_encode), \"\"])\n",
    "        summary.append([\"\", \"\"])\n",
    "    else:\n",
    "        summary.append([\"All boolean columns are encoded for ML.\", \"\"])\n",
    "        summary.append([\"\", \"\"])\n",
    "    \n",
    "    # Columns with only one unique value\n",
    "    single_value_cols = [col for col in df.columns if len(df[col].value_counts()) == 1]\n",
    "    if single_value_cols:\n",
    "        summary.append([\"Columns with only one unique value:\", \"\"])\n",
    "        summary.append([\", \".join(single_value_cols), \"\"])\n",
    "    \n",
    "    # Print summary table\n",
    "    print(tabulate(summary, headers=[\"Issue\", \"Details\"], tablefmt=\"pretty\"))\n",
    "\n",
    "dataframe_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>...</th>\n",
       "      <th>JobRole_Human Resources</th>\n",
       "      <th>JobRole_Laboratory Technician</th>\n",
       "      <th>JobRole_Manager</th>\n",
       "      <th>JobRole_Manufacturing Director</th>\n",
       "      <th>JobRole_Research Director</th>\n",
       "      <th>JobRole_Research Scientist</th>\n",
       "      <th>JobRole_Sales Executive</th>\n",
       "      <th>JobRole_Sales Representative</th>\n",
       "      <th>MaritalStatus_Married</th>\n",
       "      <th>MaritalStatus_Single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1392</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Attrition  DailyRate  DistanceFromHome  Education  EmployeeNumber  \\\n",
       "0   41          1       1102                 1          2               1   \n",
       "1   49          0        279                 8          1               2   \n",
       "2   37          1       1373                 2          2               4   \n",
       "3   33          0       1392                 3          4               5   \n",
       "4   27          0        591                 2          1               7   \n",
       "\n",
       "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  ...  \\\n",
       "0                        2       1          94               3  ...   \n",
       "1                        3       0          61               2  ...   \n",
       "2                        4       0          92               2  ...   \n",
       "3                        4       1          56               3  ...   \n",
       "4                        1       0          40               3  ...   \n",
       "\n",
       "   JobRole_Human Resources  JobRole_Laboratory Technician  JobRole_Manager  \\\n",
       "0                      0.0                            0.0              0.0   \n",
       "1                      0.0                            0.0              0.0   \n",
       "2                      0.0                            1.0              0.0   \n",
       "3                      0.0                            0.0              0.0   \n",
       "4                      0.0                            1.0              0.0   \n",
       "\n",
       "   JobRole_Manufacturing Director  JobRole_Research Director  \\\n",
       "0                             0.0                        0.0   \n",
       "1                             0.0                        0.0   \n",
       "2                             0.0                        0.0   \n",
       "3                             0.0                        0.0   \n",
       "4                             0.0                        0.0   \n",
       "\n",
       "   JobRole_Research Scientist  JobRole_Sales Executive  \\\n",
       "0                         0.0                      1.0   \n",
       "1                         1.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         1.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "\n",
       "   JobRole_Sales Representative  MaritalStatus_Married  MaritalStatus_Single  \n",
       "0                           0.0                    0.0                   1.0  \n",
       "1                           0.0                    1.0                   0.0  \n",
       "2                           0.0                    0.0                   1.0  \n",
       "3                           0.0                    1.0                   0.0  \n",
       "4                           0.0                    1.0                   0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the specified columns\n",
    "df.drop(columns=[\"EmployeeCount\", \"Over18\", \"StandardHours\"], inplace=True)\n",
    "\n",
    "# Replace \"True\" and \"False\" with 1 and 0 in Attrition and OverTime columns\n",
    "df[\"Attrition\"] = df[\"Attrition\"].replace({\"Yes\": 1, \"No\": 0})\n",
    "df[\"OverTime\"] = df[\"OverTime\"].replace({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Replace \"Male\" and \"Female\" with 0 and 1 in Gender column\n",
    "df[\"Gender\"] = df[\"Gender\"].replace({\"Male\": 0, \"Female\": 1})\n",
    "\n",
    "# Apply one-hot encoding to categorical variables\n",
    "categorical_columns = [\"BusinessTravel\", \"Department\", \"EducationField\", \"JobRole\", \"MaritalStatus\"]\n",
    "encoder = OneHotEncoder(sparse=False, drop=\"first\")\n",
    "encoded_columns = encoder.fit_transform(df[categorical_columns])\n",
    "categories = encoder.categories_\n",
    "encoded_columns_df = pd.DataFrame(encoded_columns, columns=[f\"{col}_{val}\" for col, cats in zip(categorical_columns, categories) for val in cats[1:]])\n",
    "df.drop(columns=categorical_columns, inplace=True)\n",
    "df = pd.concat([df, encoded_columns_df], axis=1)\n",
    "df_bandera = df.copy()\n",
    "\n",
    "# Print the preprocessed dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar dataset en entrenamiento y test\n",
    "X = df.drop(columns=[\"JobSatisfaction\"])\n",
    "y = df[\"JobSatisfaction\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Definir modelos y parámetros\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_svm = SVC()\n",
    "clf_gb = GradientBoostingClassifier()\n",
    "clf_ann = MLPClassifier()\n",
    "\n",
    "# Entrenar modelos\n",
    "clf_rf.fit(X_train, y_train)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "clf_gb.fit(X_train, y_train)\n",
    "clf_ann.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en conjunto de prueba y evaluar métricas\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "y_pred_gb = clf_gb.predict(X_test)\n",
    "y_pred_ann = clf_ann.predict(X_test)\n",
    "\n",
    "# Evaluar métricas\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf, average=\"weighted\")\n",
    "rec_rf = recall_score(y_test, y_pred_rf, average=\"weighted\")\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average=\"weighted\")\n",
    "\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "prec_svm = precision_score(y_test, y_pred_svm, average=\"weighted\")\n",
    "rec_svm = recall_score(y_test, y_pred_svm, average=\"weighted\")\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average=\"weighted\")\n",
    "\n",
    "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
    "prec_gb = precision_score(y_test, y_pred_gb, average=\"weighted\")\n",
    "rec_gb = recall_score(y_test, y_pred_gb, average=\"weighted\")\n",
    "f1_gb = f1_score(y_test, y_pred_gb, average=\"weighted\")\n",
    "\n",
    "acc_ann = accuracy_score(y_test, y_pred_ann)\n",
    "prec_ann = precision_score(y_test, y_pred_ann, average=\"weighted\")\n",
    "rec_ann = recall_score(y_test, y_pred_ann, average=\"weighted\")\n",
    "f1_ann = f1_score(y_test, y_pred_ann, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+----------+-----------+--------+----------+\n",
      "|                 Model                 | Accuracy | Precision | Recall | F1-Score |\n",
      "+---------------------------------------+----------+-----------+--------+----------+\n",
      "|       Random Forest Classifier:       |  0.2449  |  0.1958   | 0.2449 |  0.2072  |\n",
      "|  Support Vector Machine Classifier:   |  0.3231  |  0.2130   | 0.3231 |  0.2244  |\n",
      "|     Gradient Boosting Classifier:     |  0.2653  |  0.2461   | 0.2653 |  0.2468  |\n",
      "| Artificial Neural Network Classifier: |  0.2449  |  0.2310   | 0.2449 |  0.1890  |\n",
      "+---------------------------------------+----------+-----------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Formateamos los datos de los modelos de clasificación en forma de lista\n",
    "data_classification = [\n",
    "    [\"Random Forest Classifier:\", f\"{acc_rf:.4f}\", f\"{prec_rf:.4f}\", f\"{rec_rf:.4f}\", f\"{f1_rf:.4f}\"],\n",
    "    [\"Support Vector Machine Classifier:\", f\"{acc_svm:.4f}\", f\"{prec_svm:.4f}\", f\"{rec_svm:.4f}\", f\"{f1_svm:.4f}\"],\n",
    "    [\"Gradient Boosting Classifier:\", f\"{acc_gb:.4f}\", f\"{prec_gb:.4f}\", f\"{rec_gb:.4f}\", f\"{f1_gb:.4f}\"],\n",
    "    [\"Artificial Neural Network Classifier:\", f\"{acc_ann:.4f}\", f\"{prec_ann:.4f}\", f\"{rec_ann:.4f}\", f\"{f1_ann:.4f}\"]\n",
    "]\n",
    "\n",
    "# Imprimimos la tabla para modelos de clasificación\n",
    "print(tabulate(data_classification, headers=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"], tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 17:17:55.769397: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-26 17:17:55.769511: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-02-26 17:17:57.330484: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-26 17:17:57.611227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-26 17:17:58.123644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 17:18:13.167127: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "weights = {0: 0.6, 1: 0.4}\n",
    "\n",
    "# Definir diccionario de mapeo\n",
    "mapping = {1: 0, 2: 0, 3: 1, 4: 1}\n",
    "\n",
    "# Aplicar mapeo a los datos de entrenamiento y prueba\n",
    "y_train = y_train.map(mapping)\n",
    "y_test = y_test.map(mapping)\n",
    "\n",
    "# Definir modelos y parámetros\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_svm = SVC()\n",
    "clf_gb = GradientBoostingClassifier()\n",
    "clf_ann = MLPClassifier()\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_lr = LogisticRegression()\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_xgb = XGBClassifier()\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(45,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Entrenar modelos\n",
    "clf_rf.fit(X_train, y_train)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "clf_gb.fit(X_train, y_train)\n",
    "clf_ann.fit(X_train, y_train)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#history = model.fit(X_train, y_train, batch_size=64, epochs=100, validation_split=0.2, validation_data=(X_test, y_test), class_weight=weights)\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=100, validation_split=0.2, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "# Realizar predicciones en conjunto de prueba y evaluar métricas\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "y_pred_gb = clf_gb.predict(X_test)\n",
    "y_pred_ann = clf_ann.predict(X_test)\n",
    "y_pred_knn = clf_knn.predict(X_test)\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "y_pred_dt = clf_dt.predict(X_test)\n",
    "y_pred_xgb = clf_xgb.predict(X_test)\n",
    "y_pred_keras = model.predict(X_test)\n",
    "y_pred_keras = [1 if pred > 0.5 else 0 for pred in y_pred_keras]\n",
    "\n",
    "# Evaluar métricas\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf, average=\"weighted\")\n",
    "rec_rf = recall_score(y_test, y_pred_rf, average=\"weighted\")\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average=\"weighted\")\n",
    "tn_rf, fp_rf, fn_rf, tp_rf = confusion_matrix(y_test, y_pred_rf).ravel()\n",
    "tpr_rf = tp_rf / (tp_rf + fn_rf)\n",
    "fpr_rf = fp_rf / (fp_rf + tn_rf)\n",
    "mcc_rf = matthews_corrcoef(y_test, y_pred_rf)\n",
    "\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "prec_svm = precision_score(y_test, y_pred_svm, average=\"weighted\")\n",
    "rec_svm = recall_score(y_test, y_pred_svm, average=\"weighted\")\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average=\"weighted\")\n",
    "tn_svm, fp_svm, fn_svm, tp_svm = confusion_matrix(y_test, y_pred_svm).ravel()\n",
    "tpr_svm = tp_svm / (tp_svm + fn_svm)\n",
    "fpr_svm = fp_svm / (fp_svm + tn_svm)\n",
    "mcc_svm = matthews_corrcoef(y_test, y_pred_svm)\n",
    "\n",
    "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
    "prec_gb = precision_score(y_test, y_pred_gb, average=\"weighted\")\n",
    "rec_gb = recall_score(y_test, y_pred_gb, average=\"weighted\")\n",
    "f1_gb = f1_score(y_test, y_pred_gb, average=\"weighted\")\n",
    "tn_gb, fp_gb, fn_gb, tp_gb = confusion_matrix(y_test, y_pred_gb).ravel()\n",
    "tpr_gb = tp_gb / (tp_gb + fn_gb)\n",
    "fpr_gb = fp_gb / (fp_gb + tn_gb)\n",
    "mcc_gb = matthews_corrcoef(y_test, y_pred_gb)\n",
    "\n",
    "acc_ann = accuracy_score(y_test, y_pred_ann)\n",
    "prec_ann = precision_score(y_test, y_pred_ann, average=\"weighted\")\n",
    "rec_ann = recall_score(y_test, y_pred_ann, average=\"weighted\")\n",
    "f1_ann = f1_score(y_test, y_pred_ann, average=\"weighted\")\n",
    "tn_ann, fp_ann, fn_ann, tp_ann = confusion_matrix(y_test, y_pred_ann).ravel()\n",
    "tpr_ann = tp_ann / (tp_ann + fn_ann)\n",
    "fpr_ann = fp_ann / (fp_ann + tn_ann)\n",
    "mcc_ann = matthews_corrcoef(y_test, y_pred_ann)\n",
    "\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "prec_knn = precision_score(y_test, y_pred_knn, average=\"weighted\")\n",
    "rec_knn = recall_score(y_test, y_pred_knn, average=\"weighted\")\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average=\"weighted\")\n",
    "tn_knn, fp_knn, fn_knn, tp_knn = confusion_matrix(y_test, y_pred_knn).ravel()\n",
    "tpr_knn = tp_knn / (tp_knn + fn_knn)\n",
    "fpr_knn = fp_knn / (fp_knn + tn_knn)\n",
    "mcc_knn = matthews_corrcoef(y_test, y_pred_knn)\n",
    "\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "prec_lr = precision_score(y_test, y_pred_lr, average=\"weighted\")\n",
    "rec_lr = recall_score(y_test, y_pred_lr, average=\"weighted\")\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average=\"weighted\")\n",
    "tn_lr, fp_lr, fn_lr, tp_lr = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "tpr_lr = tp_lr / (tp_lr + fn_lr)\n",
    "fpr_lr = fp_lr / (fp_lr + tn_lr)\n",
    "mcc_lr = matthews_corrcoef(y_test, y_pred_lr)\n",
    "\n",
    "acc_dt = accuracy_score(y_test, y_pred_dt)\n",
    "prec_dt = precision_score(y_test, y_pred_dt, average=\"weighted\")\n",
    "rec_dt = recall_score(y_test, y_pred_dt, average=\"weighted\")\n",
    "f1_dt = f1_score(y_test, y_pred_dt, average=\"weighted\")\n",
    "tn_dt, fp_dt, fn_dt, tp_dt = confusion_matrix(y_test, y_pred_dt).ravel()\n",
    "tpr_dt = tp_dt / (tp_dt + fn_dt)\n",
    "fpr_dt = fp_dt / (fp_dt + tn_dt)\n",
    "mcc_dt = matthews_corrcoef(y_test, y_pred_dt)\n",
    "\n",
    "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "prec_xgb = precision_score(y_test, y_pred_xgb, average=\"weighted\")\n",
    "rec_xgb = recall_score(y_test, y_pred_xgb, average=\"weighted\")\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average=\"weighted\")\n",
    "tn_xgb, fp_xgb, fn_xgb, tp_xgb = confusion_matrix(y_test, y_pred_xgb).ravel()\n",
    "tpr_xgb = tp_xgb / (tp_xgb + fn_xgb)\n",
    "fpr_xgb = fp_xgb / (fp_xgb + tn_xgb)\n",
    "mcc_xgb = matthews_corrcoef(y_test, y_pred_xgb)\n",
    "    \n",
    "acc_nn = accuracy_score(y_test, y_pred_keras)\n",
    "prec_nn = precision_score(y_test, y_pred_keras)\n",
    "rec_nn = recall_score(y_test, y_pred_keras)\n",
    "f1_nn = f1_score(y_test, y_pred_keras)\n",
    "tn_nn, fp_nn, fn_nn, tp_nn = confusion_matrix(y_test, y_pred_keras).ravel()\n",
    "tpr_nn = tp_nn / (tp_nn + fn_nn)\n",
    "fpr_nn = fp_nn / (fp_nn + tn_nn)\n",
    "mcc_nn = matthews_corrcoef(y_test, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+----------+-----------+--------+----------+--------+--------+---------+\n",
      "|                 Model                 | Accuracy | Precision | Recall | F1-Score |  TPR   |  FPR   |   MCC   |\n",
      "+---------------------------------------+----------+-----------+--------+----------+--------+--------+---------+\n",
      "|       Random Forest Classifier:       |  0.5680  |  0.4837   | 0.5680 |  0.4946  | 0.8579 | 0.9099 | -0.0769 |\n",
      "|  Support Vector Machine Classifier:   |  0.6224  |  0.3874   | 0.6224 |  0.4776  | 1.0000 | 1.0000 | 0.0000  |\n",
      "|     Gradient Boosting Classifier:     |  0.6259  |  0.5966   | 0.6259 |  0.5805  | 0.8689 | 0.7748 | 0.1224  |\n",
      "| Artificial Neural Network Classifier: |  0.5544  |  0.5391   | 0.5544 |  0.5446  | 0.6940 | 0.6757 | 0.0191  |\n",
      "|    K-Nearest Neighbors Classifier:    |  0.5170  |  0.4965   | 0.5170 |  0.5041  | 0.6721 | 0.7387 | -0.0703 |\n",
      "|    Logistic Regression Classifier:    |  0.6088  |  0.4476   | 0.6088 |  0.4769  | 0.9727 | 0.9910 | -0.0628 |\n",
      "|       Decision Tree Classifier:       |  0.5102  |  0.5153   | 0.5102 |  0.5126  | 0.5902 | 0.6216 | -0.0312 |\n",
      "|          XGBoost Classifier:          |  0.5340  |  0.5077   | 0.5340 |  0.5161  | 0.7049 | 0.7477 | -0.0463 |\n",
      "|         Keras Neural Network:         |  0.6224  |  0.6224   | 1.0000 |  0.7673  | 1.0000 | 1.0000 | 0.0000  |\n",
      "+---------------------------------------+----------+-----------+--------+----------+--------+--------+---------+\n"
     ]
    }
   ],
   "source": [
    "# Formateamos los datos de los modelos de clasificación en forma de lista\n",
    "data_classification = [\n",
    "    [\"Random Forest Classifier:\", f\"{acc_rf:.4f}\", f\"{prec_rf:.4f}\", f\"{rec_rf:.4f}\", f\"{f1_rf:.4f}\", f\"{tpr_rf:.4f}\", f\"{fpr_rf:.4f}\", f\"{mcc_rf:.4f}\"],\n",
    "    [\"Support Vector Machine Classifier:\", f\"{acc_svm:.4f}\", f\"{prec_svm:.4f}\", f\"{rec_svm:.4f}\", f\"{f1_svm:.4f}\", f\"{tpr_svm:.4f}\", f\"{fpr_svm:.4f}\", f\"{mcc_svm:.4f}\"],\n",
    "    [\"Gradient Boosting Classifier:\", f\"{acc_gb:.4f}\", f\"{prec_gb:.4f}\", f\"{rec_gb:.4f}\", f\"{f1_gb:.4f}\", f\"{tpr_gb:.4f}\", f\"{fpr_gb:.4f}\", f\"{mcc_gb:.4f}\"],\n",
    "    [\"Artificial Neural Network Classifier:\", f\"{acc_ann:.4f}\", f\"{prec_ann:.4f}\", f\"{rec_ann:.4f}\", f\"{f1_ann:.4f}\", f\"{tpr_ann:.4f}\", f\"{fpr_ann:.4f}\", f\"{mcc_ann:.4f}\"],\n",
    "    [\"K-Nearest Neighbors Classifier:\", f\"{acc_knn:.4f}\", f\"{prec_knn:.4f}\", f\"{rec_knn:.4f}\", f\"{f1_knn:.4f}\", f\"{tpr_knn:.4f}\", f\"{fpr_knn:.4f}\", f\"{mcc_knn:.4f}\"],\n",
    "    [\"Logistic Regression Classifier:\", f\"{acc_lr:.4f}\", f\"{prec_lr:.4f}\", f\"{rec_lr:.4f}\", f\"{f1_lr:.4f}\", f\"{tpr_lr:.4f}\", f\"{fpr_lr:.4f}\", f\"{mcc_lr:.4f}\"],\n",
    "    [\"Decision Tree Classifier:\", f\"{acc_dt:.4f}\", f\"{prec_dt:.4f}\", f\"{rec_dt:.4f}\", f\"{f1_dt:.4f}\", f\"{tpr_dt:.4f}\", f\"{fpr_dt:.4f}\", f\"{mcc_dt:.4f}\"],\n",
    "    [\"XGBoost Classifier:\", f\"{acc_xgb:.4f}\", f\"{prec_xgb:.4f}\", f\"{rec_xgb:.4f}\", f\"{f1_xgb:.4f}\", f\"{tpr_xgb:.4f}\", f\"{fpr_xgb:.4f}\", f\"{mcc_xgb:.4f}\"],\n",
    "    [\"Keras Neural Network:\", f\"{acc_nn:.4f}\", f\"{prec_nn:.4f}\", f\"{rec_nn:.4f}\", f\"{f1_nn:.4f}\", f\"{tpr_nn:.4f}\", f\"{fpr_nn:.4f}\", f\"{mcc_nn:.4f}\"]\n",
    "]\n",
    "\n",
    "# Imprimimos la tabla para modelos de clasificación\n",
    "print(tabulate(data_classification, headers=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"TPR\", \"FPR\", \"MCC\"], tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "+---------------------------+-----------------------+----------------------+\n",
      "|           Model           |          MCC          |         Std          |\n",
      "+---------------------------+-----------------------+----------------------+\n",
      "|       Random Forest       | -0.008577643315988336 | 0.05491211023529826  |\n",
      "|            SVM            |  0.00797456478486514  | 0.13508075552025509  |\n",
      "|     Gradient Boosting     | -0.08896106949970788  | 0.09154106885595438  |\n",
      "| Artificial Neural Network | -0.03735850557691443  | 0.11663419109538312  |\n",
      "|    K-Nearest Neighbors    | -0.06198745807780491  | 0.045271484523537166 |\n",
      "|    Logistic Regression    | -0.09339183468031667  | 0.10584968490214237  |\n",
      "|       Decision Tree       |  -0.0731136157745358  | 0.09627215444814861  |\n",
      "|          XGBoost          | 0.013554757095022223  | 0.07700697513216834  |\n",
      "|   Keras Neural Network    | 0.0005249146420519046 | 0.027009163208402978 |\n",
      "+---------------------------+-----------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "# Realizar validación cruzada y obtener puntajes MCC\n",
    "n_repeats = 5\n",
    "scoring = 'matthews_corrcoef'\n",
    "cv_rf = cross_val_score(clf_rf, X_test, y_test, cv=n_repeats, scoring=scoring)\n",
    "cv_svm = cross_val_score(clf_rf, X_test, y_test, cv=n_repeats, scoring=scoring)\n",
    "cv_gb = cross_val_score(clf_rf, X_test, y_test, cv=n_repeats, scoring=scoring)\n",
    "cv_ann = cross_val_score(clf_rf, X_test, y_test, cv=n_repeats, scoring=scoring)\n",
    "cv_knn = cross_val_score(clf_rf, X_test, y_test, cv=n_repeats, scoring=scoring)\n",
    "cv_lr = cross_val_score(clf_rf, X_test, y_test, cv=n_repeats, scoring=scoring)\n",
    "cv_dt = cross_val_score(clf_rf, X_test, y_test, cv=n_repeats, scoring=scoring)\n",
    "cv_xgb = cross_val_score(clf_rf, X_test, y_test, cv=n_repeats, scoring=scoring)\n",
    "\n",
    "cv_keras = []\n",
    "for i in range(n_repeats):\n",
    "    model.fit(X_train, y_train, batch_size=64, epochs=100, validation_split=0.2, verbose=0)\n",
    "    y_pred_keras = model.predict(X_test)\n",
    "    y_pred_keras = [1 if pred > 0.5 else 0 for pred in y_pred_keras]\n",
    "    cv_keras.append(matthews_corrcoef(y_test, y_pred_keras))\n",
    "\n",
    "# Imprimir resultados de validación cruzada\n",
    "results = [    [\"Random Forest\", cv_rf.mean(), cv_rf.std()],\n",
    "    [\"SVM\", cv_svm.mean(), cv_svm.std()],\n",
    "    [\"Gradient Boosting\", cv_gb.mean(), cv_gb.std()],\n",
    "    [\"Artificial Neural Network\", np.mean(cv_ann), np.std(cv_ann)],\n",
    "    [\"K-Nearest Neighbors\", np.mean(cv_knn), np.std(cv_knn)],\n",
    "    [\"Logistic Regression\", np.mean(cv_lr), np.std(cv_lr)],\n",
    "    [\"Decision Tree\", np.mean(cv_dt), np.std(cv_dt)],\n",
    "    [\"XGBoost\", np.mean(cv_xgb), np.std(cv_xgb)],\n",
    "    [\"Keras Neural Network\", np.mean(cv_keras), np.std(cv_keras)]\n",
    "]\n",
    "\n",
    "headers = [\"Model\", \"MCC\", \"Std\"]\n",
    "print(tabulate(results, headers=headers, tablefmt=\"pretty\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8d892cf65759af0cb64eb5ea1aa9ab0f96e54b257dcd02666ad07491bb72211"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
